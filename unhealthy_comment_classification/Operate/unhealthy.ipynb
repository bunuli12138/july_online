{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train： \n",
    "- 英文文本+6种该评论不健康类型的概率\n",
    "- 当前评论属于那种分类，则label为1，可同时多个为1\n",
    "\n",
    "提交格式：   \n",
    "\n",
    "| id | toxic | severe_toxic | obscene | threat | insult | identity_hate |    \n",
    "| --- | --- |  --- | --- |  --- | --- |  --- |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize                               # 分词\n",
    "\n",
    "# 可视化\n",
    "import matplotlib.pyplot as plt                \n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec                                         # 词向量\n",
    "from sklearn.manifold import TSNE                                          # tsne降维\n",
    "from keras.layers import TimeDistributed, Dropout                          # \n",
    "\n",
    "from keras.models import Sequential# , Model                               # CNN初始化\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input        # CNN网络层，Dense net 等\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D                # 卷积操作，池化操作\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input               # VGG16 模型、输入预处理\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD                                           # 优化器SGD操作\n",
    "from keras.optimizers import RMSprop, Adam                                 # 优化算法RMSprop，Adam\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator                   # 图像矩阵转换\n",
    "from keras.preprocessing import image                                      # 图像处理操作\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split                       # 数据集划分\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# tensorflow环境\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143611</th>\n",
       "      <td>0c7f3197cb2998d4</td>\n",
       "      <td>Hello Cindamuse,\\n\\n1. Please review/edit the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143612</th>\n",
       "      <td>6de99309da264aee</td>\n",
       "      <td>I've restored the links to the specific subjec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143613</th>\n",
       "      <td>7390c4a88a58f72f</td>\n",
       "      <td>\"\\n\\n An-cap FAQ \\n\\nWhen making a list of ana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "143611  0c7f3197cb2998d4  Hello Cindamuse,\\n\\n1. Please review/edit the ...   \n",
       "143612  6de99309da264aee  I've restored the links to the specific subjec...   \n",
       "143613  7390c4a88a58f72f  \"\\n\\n An-cap FAQ \\n\\nWhen making a list of ana...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "143611      0             0        0       0       0              0  \n",
       "143612      0             0        0       0       0              0  \n",
       "143613      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainOrg = pd.read_csv('../Data/train_july.csv')\n",
    "df_trainOrg.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15954</th>\n",
       "      <td>020edaf0f24e861f</td>\n",
       "      <td>\"\\n\\n\"\"Actions in la-la land have real world c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15955</th>\n",
       "      <td>cf56bc027896fc22</td>\n",
       "      <td>\", 8 April 2009 (UTC)\\n\\nThanks for your conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>653ad098cf212e80</td>\n",
       "      <td>About personal attacks...I wasn't the one goin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text\n",
       "15954  020edaf0f24e861f  \"\\n\\n\"\"Actions in la-la land have real world c...\n",
       "15955  cf56bc027896fc22  \", 8 April 2009 (UTC)\\n\\nThanks for your conti...\n",
       "15956  653ad098cf212e80  About personal attacks...I wasn't the one goin..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testOrg = pd.read_csv('../Data/test_july.csv')\n",
    "df_testOrg.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143614, 8), (15957, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_trainLowLen, int_trainColLen = df_trainOrg.shape\n",
    "int_testLowLen, int_testColLen = df_testOrg.shape\n",
    "\n",
    "(int_trainLowLen, int_trainColLen), (int_testLowLen, int_testColLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143611</th>\n",
       "      <td>Hello Cindamuse,\\n\\n1. Please review/edit the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143612</th>\n",
       "      <td>I've restored the links to the specific subjec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143613</th>\n",
       "      <td>\"\\n\\n An-cap FAQ \\n\\nWhen making a list of ana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  \\\n",
       "143611  Hello Cindamuse,\\n\\n1. Please review/edit the ...      0   \n",
       "143612  I've restored the links to the specific subjec...      0   \n",
       "143613  \"\\n\\n An-cap FAQ \\n\\nWhen making a list of ana...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \n",
       "143611             0        0       0       0              0  \n",
       "143612             0        0       0       0              0  \n",
       "143613             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_trainIndexs = df_trainOrg.iloc[:,0]\n",
    "df_trainData = df_trainOrg.iloc[:, 1:]\n",
    "\n",
    "df_trainData.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15954    \"\\n\\n\"\"Actions in la-la land have real world c...\n",
       "15955    \", 8 April 2009 (UTC)\\n\\nThanks for your conti...\n",
       "15956    About personal attacks...I wasn't the one goin...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testData = df_testOrg.iloc[:, 1]\n",
    "df_testData.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15954    \"\\n\\n\"\"Actions in la-la land have real world c...\n",
       "15955    \", 8 April 2009 (UTC)\\n\\nThanks for your conti...\n",
       "15956    About personal attacks...I wasn't the one goin...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_testIndexs = df_testOrg.iloc[:,0]\n",
    "ser_testText = df_testOrg.iloc[:,1]\n",
    "\n",
    "ser_testText.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"About personal attacks...I wasn't the one going around and persecuting IP addresses...\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ser_testText.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Stalking \\n\\nyou little shit you need to stop ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>F*CK YOU \\n\\nYou moth*rfucker, if you want me ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>fuck you daniel, you big dickhead 60.241.11.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text  toxic  severe_toxic  \\\n",
       "45   Stalking \\n\\nyou little shit you need to stop ...      1             1   \n",
       "84   F*CK YOU \\n\\nYou moth*rfucker, if you want me ...      1             1   \n",
       "288     fuck you daniel, you big dickhead 60.241.11.51      1             1   \n",
       "\n",
       "     obscene  threat  insult  identity_hate  \n",
       "45         1       0       1              0  \n",
       "84         1       0       1              0  \n",
       "288        1       0       1              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainData[df_trainData['toxic'] & df_trainData['severe_toxic']==1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HELP\\n\\nMy userpage is SCREWED', severe_toxic     0\n",
       " obscene          0\n",
       " threat           0\n",
       " insult           0\n",
       " identity_hate    0\n",
       " Name: 5, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainData.iloc[5,:]['comment_text'], df_trainData.iloc[5,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "set_punt = set(string.punctuation)\n",
    "print(len(set_punt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_words</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1998, NFC, Championship, This, game, should, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[and, I, removed, the, matter, of, fact, state...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Congratulations, on, making, the, news, and, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cut_words  toxic  severe_toxic  \\\n",
       "0  [1998, NFC, Championship, This, game, should, ...      0             0   \n",
       "1  [and, I, removed, the, matter, of, fact, state...      0             0   \n",
       "2  [Congratulations, on, making, the, news, and, ...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集分词\n",
    "l = []\n",
    "c = ['cut_words', 'toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "# label一致化\n",
    "df_trainCW = pd.DataFrame(columns=c)\n",
    "for n in c[1:]:\n",
    "    df_trainCW[n] = df_trainData[n]\n",
    "\n",
    "# 分词\n",
    "for sen in df_trainData['comment_text']:\n",
    "    s_l = wordpunct_tokenize(sen)\n",
    "    l.append([w for w in s_l if w not in set_punt])\n",
    "df_trainCW['cut_words'] = l\n",
    "\n",
    "df_trainCW.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [This, message, is, regarding, the, page, Play...\n",
       "1    [This, message, is, regarding, the, page, Play...\n",
       "2    [I, think, this, article, needs, a, little, up...\n",
       "Name: cut_words, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集分词\n",
    "l = []\n",
    "ser_testCW = pd.Series()\n",
    "\n",
    "# 分词\n",
    "for sen in df_testData:\n",
    "    s_l = wordpunct_tokenize(sen)\n",
    "    l.append([w for w in s_l if w not in set_punt])\n",
    "    l.append(wordpunct_tokenize(sen))\n",
    "ser_testCW = pd.Series(l, name='cut_words')\n",
    "\n",
    "ser_testCW.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612c0c93a5ca94db</td>\n",
       "      <td>[This, message, is, regarding, the, page, Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d5567adaddbc78cb</td>\n",
       "      <td>[This, message, is, regarding, the, page, Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85b845308824202b</td>\n",
       "      <td>[I, think, this, article, needs, a, little, up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          cut_words\n",
       "0  612c0c93a5ca94db  [This, message, is, regarding, the, page, Play...\n",
       "1  d5567adaddbc78cb  [This, message, is, regarding, the, page, Play...\n",
       "2  85b845308824202b  [I, think, this, article, needs, a, little, up..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testProed = pd.DataFrame(columns=['id', 'cut_words'])\n",
    "df_testProed['id'] = ser_testIndexs\n",
    "df_testProed['cut_words'] = ser_testCW\n",
    "df_testProed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cut_words</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07b9e910cc401c3c</td>\n",
       "      <td>[1998, NFC, Championship, This, game, should, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a80141fb5bae14ea</td>\n",
       "      <td>[and, I, removed, the, matter, of, fact, state...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d5c63ba045a058a</td>\n",
       "      <td>[Congratulations, on, making, the, news, and, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          cut_words  toxic  \\\n",
       "0  07b9e910cc401c3c  [1998, NFC, Championship, This, game, should, ...      0   \n",
       "1  a80141fb5bae14ea  [and, I, removed, the, matter, of, fact, state...      0   \n",
       "2  1d5c63ba045a058a  [Congratulations, on, making, the, news, and, ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "df_trainProed = deepcopy(df_trainCW)\n",
    "df_trainProed.insert(0, 'id', value=ser_trainIndexs)\n",
    "\n",
    "df_trainProed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06082352\n"
     ]
    }
   ],
   "source": [
    "# 导出分词结果\n",
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "s = datetime.strftime(t, '%m%d%H%M')\n",
    "print(s)\n",
    "\n",
    "# df_trainProed.to_csv('../Data/CW_train_06082300.csv', sep=',', index=None)\n",
    "# df_testProed.to_csv('../Data/CW_test_06082300.csv', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单词词向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trainProed = pd.read_csv('../Data/CW_train_06082300.csv')\n",
    "# df_testProed = pd.read_csv('../Data/CW_test_06082300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cut_words</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07b9e910cc401c3c</td>\n",
       "      <td>[1998, NFC, Championship, This, game, should, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a80141fb5bae14ea</td>\n",
       "      <td>[and, I, removed, the, matter, of, fact, state...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d5c63ba045a058a</td>\n",
       "      <td>[Congratulations, on, making, the, news, and, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          cut_words  toxic  \\\n",
       "0  07b9e910cc401c3c  [1998, NFC, Championship, This, game, should, ...      0   \n",
       "1  a80141fb5bae14ea  [and, I, removed, the, matter, of, fact, state...      0   \n",
       "2  1d5c63ba045a058a  [Congratulations, on, making, the, news, and, ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainProed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612c0c93a5ca94db</td>\n",
       "      <td>[This, message, is, regarding, the, page, Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d5567adaddbc78cb</td>\n",
       "      <td>[This, message, is, regarding, the, page, Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85b845308824202b</td>\n",
       "      <td>[I, think, this, article, needs, a, little, up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          cut_words\n",
       "0  612c0c93a5ca94db  [This, message, is, regarding, the, page, Play...\n",
       "1  d5567adaddbc78cb  [This, message, is, regarding, the, page, Play...\n",
       "2  85b845308824202b  [I, think, this, article, needs, a, little, up..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testProed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 训练集单词转为50维词向量\n",
    "model_train = Word2Vec(df_trainProed['cut_words'], size=50)\n",
    "\n",
    "# 词向量列表vocab_train\n",
    "vocab_train = model_train.wv.vocab\n",
    "\n",
    "type(model_train), type(vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 测试集单词转为50维词向量\n",
    "model_test = Word2Vec(df_testProed['cut_words'], size=50)\n",
    "\n",
    "# 词向量列表\n",
    "vocab_test = model_test.wv.vocab\n",
    "\n",
    "type(model_test), type(vocab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06082353\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "s = datetime.strftime(t, '%m%d%H%M')\n",
    "print(s)\n",
    "\n",
    "# 导出词向量\n",
    "# model_train.save('../Model/DRM50_%s.model_train.bin'%s)\n",
    "# model_test.save('../Model/DRM50_%s.model_test.bin'%s)\n",
    "\n",
    "# 导入模型\n",
    "# new_model = Word2Vec.load('../Model/model_DRM50.model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(gensim.models.word2vec.Word2Vec, gensim.models.word2vec.Word2Vec)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入模型\n",
    "# model_train = Word2Vec.load('../Model/DRM50_06081800.model_train.bin')\n",
    "# model_test = Word2Vec.load('../Model/DRM50_06081800.model_test.bin')\n",
    "\n",
    "type(model_train), type(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词向量列表vocab_train\n",
    "vocab_train = model_train.wv.vocab\n",
    "\n",
    "vocab_test = model_test.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(count:237, index:3513, sample_int:4294967296)\n",
      "Vocab(count:3400, index:355, sample_int:4294967296)\n"
     ]
    }
   ],
   "source": [
    "print(str(vocab_train['1998']))\n",
    "print(str(vocab_train['matter']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100529,), (100529, 6), (43085,), (43085, 6))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_trainSize = int(0.7 * int_trainLowLen)\n",
    "X_train_train, y_train_train = df_trainProed.iloc[:int_trainSize,1], df_trainProed.iloc[:int_trainSize,2:]\n",
    "X_test_train, y_test_train = df_trainProed.iloc[int_trainSize:,1], df_trainProed.iloc[int_trainSize:,2:]\n",
    "\n",
    "X_train_train.shape, y_train_train.shape, X_test_train.shape, y_test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1998, NFC, Championship, This, game, should, ...\n",
       "1    [and, I, removed, the, matter, of, fact, state...\n",
       "2    [Congratulations, on, making, the, news, and, ...\n",
       "3    [Be, er, Sheva, North, Railway, Station, An, e...\n",
       "4    [Speedy, deletion, of, Moviedoody, A, tag, has...\n",
       "Name: cut_words, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length 1\n",
      "max length 1411\n"
     ]
    }
   ],
   "source": [
    "# 句子最大最小长度\n",
    "print('min length', len(min(list(X_train_train)+list(X_test_train), key=len)))\n",
    "print('max length', len(max(list(X_train_train)+list(X_test_train), key=len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vocab(count:237, index:3513, sample_int:4294967296)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "# 自定义方法，用id进行训练\n",
    "def getWordIndexs(l_tW, voc_t):\n",
    "    t_l = []\n",
    "    for sen in l_tW:\n",
    "        l = []\n",
    "        for w in sen:\n",
    "            if w in voc_t.keys():\n",
    "                r = re.compile('\\d*')\n",
    "                s_l = [n for n in r.findall(str(voc_t[w])) if len(n)]\n",
    "#             print(s_l)\n",
    "    \n",
    "            l.append(int(s_l[1]))\n",
    "        t_l.append(l)\n",
    "    return t_l\n",
    "\n",
    "# test\n",
    "l = getWordIndexs(list(X_train_train)[:100], vocab_train)\n",
    "len(list(X_train_train)[0]), len(list(X_train_train)[1]), len(l[0]), len(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100529,), (43085,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_train.shape, X_test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 训练集转为id list\n",
    "X_train_train_id = getWordIndexs(list(X_train_train), vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 测试集转为id list\n",
    "X_test_train_id = getWordIndexs(list(X_test_train), vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 目标集转为id list\n",
    "X_test_id = getWordIndexs(list(df_testProed['cut_words']), vocab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100529 43\n",
      "43085 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15957, 30)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_train_train_id), len(X_train_train_id[0]))\n",
    "print(len(X_test_train_id), len(X_test_train_id[0]))\n",
    "len(X_test_id), len(X_test_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充序列（Pad sequences）为长度500\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 500\n",
    "X_train_train_pad = sequence.pad_sequences(X_train_train_id, maxlen=max_words)\n",
    "X_test_train_pad = sequence.pad_sequences(X_test_train_id, maxlen=max_words)\n",
    "X_test_pad = sequence.pad_sequences(X_test_id, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100529, 500), (500,), numpy.ndarray, (15957, 500))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_train_pad.shape, X_train_train_pad[0].shape, type(X_train_train_pad[0]), X_test_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 200)          20105800  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 20,231,556\n",
      "Trainable params: 20,231,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 设计情感分析的RNN模型\n",
    "## 输入是一个最大长度为 max_words的单词序列(技术上说，序列中的整数为单词id)，我们的输出是一个二进制情感标签(0或1)。\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "embedding_size = 200\n",
    "model=Sequential()\n",
    "model.add(Embedding(100529, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "# model.add(TimeDistributed(Dropout(0.2)))\n",
    "# model.add(TimeDistributed(Dense(label_size, activation='softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过指定在训练时使用的损失函数和优化器以及我们想要测量的任何评估指标来编译我们的模型\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "rmsprop = RMSprop(lr=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100529 samples, validate on 43085 samples\n",
      "Epoch 1/5\n",
      "100529/100529 [==============================] - 1158s 12ms/step - loss: 0.2253 - acc: 0.9633 - val_loss: 0.2240 - val_acc: 0.9664\n",
      "Epoch 2/5\n",
      "100529/100529 [==============================] - 1198s 12ms/step - loss: 0.2222 - acc: 0.9652 - val_loss: 0.2253 - val_acc: 0.9642\n",
      "Epoch 3/5\n",
      "100529/100529 [==============================] - 1217s 12ms/step - loss: 0.2210 - acc: 0.9661 - val_loss: 0.2243 - val_acc: 0.9634\n",
      "Epoch 4/5\n",
      "100529/100529 [==============================] - 1195s 12ms/step - loss: 0.2207 - acc: 0.9669 - val_loss: 0.2234 - val_acc: 0.9640\n",
      "Epoch 5/5\n",
      "100529/100529 [==============================] - 1194s 12ms/step - loss: 0.2202 - acc: 0.9670 - val_loss: 0.2269 - val_acc: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x85992860>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "## 必须指定两个重要的训练参数——批处理大小（batch size）和训练周期的数量（number of training epochs），\n",
    "## 它们与我们的模型体系结构一起决定了总的训练时间\n",
    "model.fit(X_train_train_pad, y_train_train, validation_data=(X_test_train_pad, y_test_train), batch_size=200, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../Model/model_0609_.pkl', 'wb')as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\setup_space_all\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\setup_space_all\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../Model/model_0608_9668.pkl', 'rb')as f:\n",
    "    model_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 预测，y_test_train\n",
    "lst_pred_y = model.predict(X_test_train_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.82848200e-01, 1.60511643e-01, 1.65502951e-01, 1.63118601e-01,\n",
       "        1.63074300e-01, 1.64944291e-01],\n",
       "       [1.82906970e-01, 1.59937710e-01, 1.65590256e-01, 1.63054690e-01,\n",
       "        1.63509399e-01, 1.65000975e-01],\n",
       "       [1.81877807e-01, 1.60251856e-01, 1.65426418e-01, 1.63436890e-01,\n",
       "        1.63626999e-01, 1.65379971e-01],\n",
       "       [7.87857413e-01, 1.35413697e-03, 1.76545326e-02, 1.77339297e-02,\n",
       "        1.62244052e-01, 1.31559698e-02],\n",
       "       [8.35841835e-01, 5.97282451e-07, 1.22153135e-02, 7.08516694e-08,\n",
       "        1.51872486e-01, 6.97427458e-05],\n",
       "       [1.85793012e-01, 1.59601241e-01, 1.65704131e-01, 1.62240148e-01,\n",
       "        1.62756830e-01, 1.63904622e-01],\n",
       "       [1.89592183e-01, 1.54954761e-01, 1.67352289e-01, 1.63048029e-01,\n",
       "        1.63627610e-01, 1.61425143e-01],\n",
       "       [2.69826561e-01, 1.15423135e-01, 1.53852746e-01, 1.43993840e-01,\n",
       "        1.75964937e-01, 1.40938789e-01],\n",
       "       [2.04441547e-01, 1.46692440e-01, 1.70313820e-01, 1.61634475e-01,\n",
       "        1.62613675e-01, 1.54304102e-01],\n",
       "       [1.93702355e-01, 1.59838021e-01, 1.61355272e-01, 1.64142564e-01,\n",
       "        1.59772888e-01, 1.61188856e-01]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_pred_y[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100539</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100540</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100542</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100543</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100546</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100547</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100548</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "100539      0             0        0       0       0              0\n",
       "100540      0             0        0       0       0              0\n",
       "100541      0             0        0       0       0              0\n",
       "100542      1             1        1       1       1              0\n",
       "100543      1             0        0       0       1              0\n",
       "100544      0             0        0       0       0              0\n",
       "100545      0             0        0       0       0              0\n",
       "100546      0             0        0       0       0              0\n",
       "100547      0             0        0       0       0              0\n",
       "100548      0             0        0       0       0              0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test_train,lst_pred_y\n",
    "y_test_train[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 预测\n",
    "lst_pred = model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.8327398e-03 6.3413382e-04 2.7644634e-03 6.4554811e-04 3.0838251e-03\n",
      "  1.0440946e-03]\n",
      " [9.2369020e-03 6.1842799e-04 2.6097894e-03 6.2918663e-04 2.9490888e-03\n",
      "  1.0091364e-03]\n",
      " [1.0663837e-02 6.2063336e-04 2.9734671e-03 6.6053867e-04 3.2097399e-03\n",
      "  1.0970235e-03]\n",
      " [1.1783272e-02 6.6518784e-04 3.2051206e-03 6.9475174e-04 3.4865141e-03\n",
      "  1.1422038e-03]\n",
      " [4.0790141e-03 3.8927794e-04 1.5596151e-03 6.8193674e-04 1.4919043e-03\n",
      "  6.3937902e-04]\n",
      " [3.7895441e-03 3.8966537e-04 1.4776886e-03 6.6462159e-04 1.4690757e-03\n",
      "  6.0981512e-04]\n",
      " [9.1635561e-01 2.5296253e-01 8.3488011e-01 7.1524084e-02 8.0582464e-01\n",
      "  1.2031531e-01]\n",
      " [9.1497743e-01 3.0999711e-01 8.3989817e-01 9.0931535e-02 8.0369341e-01\n",
      "  1.4614975e-01]\n",
      " [1.3026327e-02 7.5641274e-04 3.2509267e-03 7.4303150e-04 3.9570928e-03\n",
      "  1.1475980e-03]\n",
      " [1.3978660e-02 8.0808997e-04 3.4156442e-03 7.7527761e-04 4.2277575e-03\n",
      "  1.1887848e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(lst_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " array([0.9163556 , 0.25296253, 0.8348801 , 0.07152408, 0.80582464,\n",
       "        0.12031531], dtype=float32),\n",
       " 0.9163556)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lst_pred), type(lst_pred[6]), lst_pred[6], lst_pred[6][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r = []\n",
    "node = 0.9\n",
    "for res in lst_pred:\n",
    "    s_l_r = []\n",
    "    for n in res:\n",
    "        if n>node:\n",
    "            s_l_r.append(1)\n",
    "        else:\n",
    "            s_l_r.append(0)\n",
    "    l_r.append(s_l_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_r[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612c0c93a5ca94db</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d5567adaddbc78cb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85b845308824202b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id toxic severe_toxic obscene threat insult identity_hate\n",
       "0  612c0c93a5ca94db   NaN          NaN     NaN    NaN    NaN           NaN\n",
       "1  d5567adaddbc78cb   NaN          NaN     NaN    NaN    NaN           NaN\n",
       "2  85b845308824202b   NaN          NaN     NaN    NaN    NaN           NaN"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(columns=['id', 'toxic','severe_toxic','obscene','threat','insult','identity_hate'])\n",
    "\n",
    "df_result['id'] = ser_testIndexs\n",
    "\n",
    "df_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id toxic severe_toxic obscene threat insult identity_hate\n",
      "6  6363aa197bb2e5de   NaN          NaN     NaN    NaN    NaN           NaN\n",
      "7  c76b950dc55f58b7   NaN          NaN     NaN    NaN    NaN           NaN\n",
      "8  40434968e59e4ecc   NaN          NaN     NaN    NaN    NaN           NaN\n",
      "9  b12e69c34d679a8e   NaN          NaN     NaN    NaN    NaN           NaN\n",
      "[[1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
      "1\t0\t0\t0\t0\t0\t\n",
      "1\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6363aa197bb2e5de</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c76b950dc55f58b7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40434968e59e4ecc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b12e69c34d679a8e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id toxic severe_toxic obscene threat insult identity_hate\n",
       "6  6363aa197bb2e5de     1            0       0      0      0             0\n",
       "7  c76b950dc55f58b7     1            0       0      0      0             0\n",
       "8  40434968e59e4ecc     0            0       0      0      0             0\n",
       "9  b12e69c34d679a8e     0            0       0      0      0             0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  deepcopy(df_result).iloc[6:10]\n",
    "l = l_r[6:10]\n",
    "print(df)\n",
    "print(l)\n",
    "\n",
    "lst_labelNames = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "for i in range(len(l)):\n",
    "    for j in range(len(lst_labelNames)):\n",
    "#         print(i, j, end='\\t')\n",
    "        print(l[i][j],end='\\t')\n",
    "        df.iloc[i,j+1] = l[i][j]\n",
    "    print()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id toxic severe_toxic obscene threat insult identity_hate\n",
      "0  612c0c93a5ca94db     0            0       0      0      0             0\n",
      "1  d5567adaddbc78cb     0            0       0      0      0             0\n",
      "2  85b845308824202b     0            0       0      0      0             0\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lst_labelNames = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "for i in range(len(l_r)):\n",
    "    for j in range(len(lst_labelNames)):\n",
    "        df_result.iloc[i,j+1] = l_r[i][j]\n",
    "\n",
    "print(df_result.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6363aa197bb2e5de</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c76b950dc55f58b7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40434968e59e4ecc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b12e69c34d679a8e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id toxic severe_toxic obscene threat insult identity_hate\n",
       "6  6363aa197bb2e5de     1            0       0      0      0             0\n",
       "7  c76b950dc55f58b7     1            0       0      0      0             0\n",
       "8  40434968e59e4ecc     0            0       0      0      0             0\n",
       "9  b12e69c34d679a8e     0            0       0      0      0             0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.iloc[6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('../Result/result_06090050.csv', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单列预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'toxic', 'severe_toxic','obscene','threat','insult','identity_hate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_train_toxic                 = y_train_train.iloc[:, 0]\n",
    "y_train_train_severe_toxic          = y_train_train.iloc[:, 1]\n",
    "y_train_train_obscene               = y_train_train.iloc[:, 2]\n",
    "y_train_train_threat                = y_train_train.iloc[:, 3]\n",
    "y_train_train_insult                = y_train_train.iloc[:, 4]\n",
    "y_train_train_identity_hate         = y_train_train.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic severe_toxic obscene threat insult identity_hate\n"
     ]
    }
   ],
   "source": [
    "print(y_train_train_toxic.name,\n",
    "y_train_train_severe_toxic.name,\n",
    "y_train_train_obscene.name,\n",
    "y_train_train_threat.name,\n",
    "y_train_train_insult.name,\n",
    "y_train_train_identity_hate.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_train_toxic                 = y_test_train.iloc[:, 0]\n",
    "y_test_train_severe_toxic          = y_test_train.iloc[:, 1]\n",
    "y_test_train_obscene               = y_test_train.iloc[:, 2]\n",
    "y_test_train_threat                = y_test_train.iloc[:, 3]\n",
    "y_test_train_insult                = y_test_train.iloc[:, 4]\n",
    "y_test_train_identity_hate         = y_test_train.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic severe_toxic obscene threat insult identity_hate\n"
     ]
    }
   ],
   "source": [
    "print(y_test_train_toxic.name,\n",
    "y_test_train_severe_toxic.name,\n",
    "y_test_train_obscene.name,\n",
    "y_test_train_threat.name,\n",
    "y_test_train_insult.name,\n",
    "y_test_train_identity_hate.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_train_train_toxic)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_10: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-7d1382571830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_toxic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100529\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_toxic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_toxic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel_toxic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_10: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "embedding_size = 100\n",
    "model_toxic =Sequential()\n",
    "model_toxic.add(Embedding(100529, embedding_size, input_length=max_words))\n",
    "model_toxic.add(LSTM(300))\n",
    "\n",
    "model_toxic.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "model_toxic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_toxic.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "rmsprop = RMSprop(lr=0.01)\n",
    "model_toxic.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100529 samples, validate on 43085 samples\n",
      "Epoch 1/1\n",
      "  2000/100529 [..............................] - ETA: 1:53:09 - loss: 14.4199 - acc: 0.0955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-ff9328d4cf3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_toxic.fit(X_train_train_pad, list(y_train_train_toxic), validation_data=(X_test_train_pad, list(y_test_train_toxic)), \n\u001b[1;32m----> 2\u001b[1;33m                 batch_size=200, epochs=1)\n\u001b[0m",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup_space_all\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_toxic.fit(X_train_train_pad, list(y_train_train_toxic), validation_data=(X_test_train_pad, list(y_test_train_toxic)), \n",
    "                batch_size=200, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
